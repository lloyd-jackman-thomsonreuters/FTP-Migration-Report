{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ftplib import FTP\n",
    "from ftputil import FTPHost\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import tables\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This section sets the location variables used throughout the rest of the report\n",
    "plano_local_dir = (\"C:\\\\Users\\\\u0136211\\\\Documents\\\\FTP Logs\\\\Plano\\\\\")\n",
    "ftp2_local_dir = (\"C:\\\\Users\\\\u0136211\\\\Documents\\\\FTP Logs\\\\FTP2\\\\\")\n",
    "ftp1_local_dir = (\"C:\\\\Users\\\\u0136211\\\\Documents\\\\FTP Logs\\\\FTP1\\\\\")\n",
    "lgftp_local_dir =(\"C:\\\\Users\\\\u0136211\\\\Documents\\\\FTP Logs\\\\LGFTP\\\\\")\n",
    "graphs = (\"C:\\\\Users\\\\u0136211\\\\Documents\\\\FTP Logs\\\\Graphs\\\\\")\n",
    "lgdf_output = \"C:\\\\Users\\\\u0136211\\\\Documents\\\\FTP Logs\\\\LGDF Plano FTP usage.xlsx\"\n",
    "ldfs_output = \"C:\\\\Users\\\\u0136211\\\\Documents\\\\FTP Logs\\\\LDFS Plano FTP usage.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_logs(ftp_site, ftp_dir, ftp_u, ftp_p, loc_dir):\n",
    "    \n",
    "    ftp = FTP(ftp_site, ftp_u, ftp_p)\n",
    "    ftp.cwd(ftp_dir)\n",
    "    ftp_logs = []\n",
    "    \n",
    "    for item in ftp.mlsd():\n",
    "        if item[0] == \"\": continue\n",
    "        if item[1][\"type\"] != \"file\": continue\n",
    "        file = item[0]\n",
    "        file_size = item[1][\"size\"]\n",
    "        file_yyyymm = int(item[1][\"modify\"])\n",
    "        if not file_yyyymm >= 20170501000000: continue\n",
    "        log = (file, file_size)\n",
    "        ftp_logs.append(log)\n",
    "    \n",
    "    os.chdir(loc_dir)\n",
    "    local_logs = set()\n",
    "    for file in os.listdir(loc_dir):\n",
    "        if not \"log\" in file: continue\n",
    "        file_size = str(os.stat(loc_dir + file).st_size)\n",
    "        log = (file, file_size)\n",
    "        local_logs.add(log)\n",
    "    \n",
    "    for log in ftp_logs:\n",
    "        if log not in local_logs:\n",
    "            print(\"Downloading \" + log[0] + \" with \" + str(log[1]) + \" bytes\")\n",
    "            local_filename = os.path.join(loc_dir, log[0])\n",
    "            f = open(local_filename, 'wb')\n",
    "            ftp.retrbinary('RETR ' + log[0], f.write, 262144)\n",
    "            f.close()\n",
    "    \n",
    "    ftp.quit()\n",
    "    print(loc_dir + \" updated successfully\")\n",
    "\n",
    "#As LGFTP doesn't support MLSD commands, this slightly different approach using the modified date comparison is used\n",
    "def update_logs_lgftp(ftp_site, ftp_dir, ftp_u, ftp_p, loc_dir):\n",
    "    \n",
    "    with FTPHost(ftp_site, ftp_u, ftp_p) as ftph:\n",
    "        for log in ftph.listdir(ftph.curdir):\n",
    "            if not \"xferlog\" in log: continue\n",
    "            print(\"Processing \"+log)\n",
    "            ftph.download_if_newer(log, (loc_dir+log))\n",
    "    print(loc_dir + \" updated successfully\")\n",
    "\n",
    "#This process takes a file with positions on a new line and returns a Python list, pritning the length of it to the screen\n",
    "def user_lists(file):\n",
    "\n",
    "    users = []\n",
    "\n",
    "    for user in open(file):\n",
    "        if user[-1] == \"\\n\":\n",
    "            if len(user[:-1]) == 0: continue\n",
    "            users.append(user[:-1])\n",
    "        else:\n",
    "            if len(user) == 0: continue\n",
    "            users.append(user)\n",
    "    print(len(users))\n",
    "    return users\n",
    "\n",
    "#This process creates an array based on the number of unique User positions are cumulatively summed, expanding from the 1st row\n",
    "def expanding_nunique(z):\n",
    "    unique_users = set()\n",
    "    expanding_nunique_list = []\n",
    "    for x in range(len(z.User)):\n",
    "        unique_users.add(z.User.iloc[x])\n",
    "        current_number = len(unique_users)\n",
    "        expanding_nunique_list.append(current_number)\n",
    "    return np.array(expanding_nunique_list)\n",
    "\n",
    "#This process creates a plot of 3 graphs, summarising migration progress in various aspects and saving the plot to .png in the specified graphs folder\n",
    "def overall(profile, users, df):\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=1)\n",
    "    df['FTP'] = df['FTP'].astype('str')\n",
    "    df = df[df.User.isin(users)]\n",
    "    df = df[df.Date > '2017-04-30']\n",
    "    temp0 = plano_df[plano_df.User.isin(users)]\n",
    "    temp0['Active Users'] = expanding_nunique(temp0)\n",
    "    temp0['Total Users'] = len(users)\n",
    "    temp_piv0 = pd.pivot_table(temp0.set_index('Date').to_period('D'), index=['Date'], columns = ['FTP'], values = ['Active Users', 'Total Users'], aggfunc=max, fill_value = 0)\n",
    "    temp_piv0.plot(ax=axes[0], title = \"%s Users' Plano Migration Progress\" %profile, figsize = (10,15), colormap = 'copper', ylim=(0, (len(users)*1.1)))\n",
    "    temp_piv = pd.pivot_table(df, index=['Date'], columns = ['FTP'], values = ['Bytes'], aggfunc=np.sum, fill_value = 0)\n",
    "    temp_piv = temp_piv.resample('W').mean()\n",
    "    temp_piv.plot(ax=axes[1], title=\"%s Consumption\\nWeekly sampled\" % profile, figsize = (10,15), colormap = 'copper', ylim = (0))\n",
    "    temp_piv2 = pd.pivot_table(df.set_index('Date').to_period('W'), index=['Date'], columns = ['FTP'], values = ['User'], aggfunc=pd.Series.nunique, fill_value = 0)\n",
    "    temp_piv2.plot(ax=axes[2], title=\"%s Users\\nWeekly sampled\" % profile, figsize = (10,15), colormap = 'copper', ylim = (0))\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(graphs+('Overall %s.png' % profile))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_logs(\"lipperftp.thomsonreuters.com\", \"/Logs/\", pln_ftp_u, pln_ftp_p, plano_local_dir)\n",
    "update_logs(\"ftp2.lipper.reuters.com\", \"/Logs1/\", ftp2_u, ftp2_p, ftp2_local_dir)\n",
    "update_logs(\"ftp2.lipper.reuters.com\", \"/Logs2/\", ftp2_u, ftp2_p, ftp1_local_dir)\n",
    "#update_logs_lgftp(\"216.88.130.18\", \"/\", lftp_p, lgftp_p, lgftp_local_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Plano FTP logs dataframe\n",
    "dfs = {}\n",
    "\n",
    "for file in os.listdir(plano_local_dir):\n",
    "    if not file.endswith(\".log\"): continue\n",
    "    if not file > \"u_ex170430.log\": continue\n",
    "    dfs[file] = pd.read_csv(plano_local_dir+file, sep = \" \", skiprows = 4, index_col = False, na_values=[\"-\", \"NaN\", \"-a92\"],\\\n",
    "                            names=[\"Date\", \"Time\", \"IP\", \"Port\", \"User\", \"Method\", \"Stem\", \"Query\", \"Status\", \"FTP Bytes\", \"SFTP Bytes\", \"File Name\", \"Port\"],\\\n",
    "                           dtype={\"Date\":np.object, \"Time\":np.object, \"IP\":np.object, \"Port\":np.object, \"User\":np.object, \"Method\":np.object, \"Stem\":np.object, \"Query\":np.object, \"Status\":np.object, \"FTP Bytes\":np.float64, \"SFTP Bytes\":np.float64, \"File Name\":np.object, \"Port\":np.object},\\\n",
    "                           error_bad_lines=False, warn_bad_lines=True)\n",
    "    dfs[file] = dfs[file].drop_duplicates()\n",
    "\n",
    "plano_df = pd.concat(dfs.values())\n",
    "plano_df = plano_df.drop_duplicates()\n",
    "plano_df['Action'] = plano_df['Method'].str.split(']').str.get(1)\n",
    "plano_df = plano_df[plano_df.Action == 'sent']\n",
    "plano_df['Date'] = pd.to_datetime(plano_df['Date'], yearfirst=True)\n",
    "plano_df = plano_df.sort_values(['Date', 'Time'])\n",
    "plano_df[\"FTP Bytes\"] = pd.to_numeric(plano_df[\"FTP Bytes\"], errors='coerce')\n",
    "plano_df[\"SFTP Bytes\"] = pd.to_numeric(plano_df[\"SFTP Bytes\"], errors='coerce')\n",
    "plano_df  = plano_df.fillna(value=0)\n",
    "plano_df['Bytes'] = plano_df['FTP Bytes'] + plano_df['SFTP Bytes']\n",
    "plano_df['FTP'] = 'Plano'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the ftp1 logs dataframe\n",
    "dfs = {}\n",
    "for file in os.listdir(ftp1_local_dir):\n",
    "    if not file.endswith(\".log\"): continue\n",
    "    if not file > \"u_ex170430.log\": continue\n",
    "    dfs[file] = pd.read_csv(ftp1_local_dir+file, sep = \" \", na_values = \"-\", comment='#', skiprows = 4, dtype='object', names=[\"Date\", \"Time\",\"IP\", \"Action\", \"File_Name\", \"?\", \"Port\", \"User\", \"IP\", \"Method\", \"Status\", \"Status\", \"Status\", \"Bytes\"])\n",
    "    dfs[file] = dfs[file].drop_duplicates()\n",
    "\n",
    "ftp1_df = pd.concat(dfs.values())\n",
    "ftp1_df = ftp1_df.drop_duplicates()\n",
    "ftp1_df = ftp1_df[ftp1_df.Action == 'GET']\n",
    "ftp1_df.Bytes  = ftp1_df.Bytes.fillna(value=0)\n",
    "ftp1_df['FTP'] = 'FTP1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the FTP2 logs dataframe\n",
    "dfs = {}\n",
    "\n",
    "for file in os.listdir(ftp2_local_dir):\n",
    "    if not file.endswith(\".log\"): continue\n",
    "    if not file > \"u_ex170430.log\": continue\n",
    "    dfs[file] = pd.read_csv(ftp2_local_dir+file, sep = \" \", na_values = \"-\", skiprows = 4, index_col = False, names=[\"Date\", \"Time\", \"IP\", \"Port\", \"User\", \"Method\", \"Stem\", \"Query\", \"Status\", \"FTP Bytes\", \"SFTP Bytes\", \"File Name\", \"Port\"])\n",
    "    dfs[file] = dfs[file].drop_duplicates()\n",
    "\n",
    "ftp2_df = pd.concat(dfs.values())\n",
    "ftp2_df = ftp2_df.drop_duplicates()\n",
    "ftp2_df['User'] = ftp2_df['User'].str.split('\\\\').str.get(1)\n",
    "ftp2_df['Action'] = ftp2_df['Method'].str.split(']').str.get(1)\n",
    "ftp2_df = ftp2_df[ftp2_df.Action == 'sent']\n",
    "ftp2_df['Date'] = pd.to_datetime(ftp2_df['Date'], yearfirst=True)\n",
    "ftp2_df = ftp2_df.sort_values(['Date', 'Time'])\n",
    "ftp2_df[\"FTP Bytes\"] = pd.to_numeric(ftp2_df[\"FTP Bytes\"], errors='coerce')\n",
    "ftp2_df[\"SFTP Bytes\"] = pd.to_numeric(ftp2_df[\"SFTP Bytes\"], errors='coerce')\n",
    "ftp2_df  = ftp2_df.fillna(value=0)\n",
    "ftp2_df['Bytes'] = ftp2_df['FTP Bytes'] + ftp2_df['SFTP Bytes']\n",
    "ftp2_df['FTP'] = 'FTP2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the LGFTP logs dataframe\n",
    "dfs = {}\n",
    "lgftp_headers = [\"Date\", \"Transfer-Time\", \"IP\", \"Bytes\", \"File_Name\", \"Transfer-Type\", \"Special-Action-Flag\", \"Direction\", \"Access-Mode\", \"User\", \"Connection\", \"0\", \"*\", \"Completion-Status\"]\n",
    "\n",
    "for file in os.listdir(lgftp_local_dir):\n",
    "    if not 'xfer' in file: continue\n",
    "    dfs[file] = pd.read_csv(lgftp_local_dir+file, delim_whitespace=True, parse_dates=[[0,1,2,3,4]], error_bad_lines=False, )\n",
    "    dfs[file].columns = lgftp_headers\n",
    "    dfs[file] = dfs[file].drop_duplicates()\n",
    "\n",
    "lgftp_df = pd.concat(dfs.values())\n",
    "lgftp_df = lgftp_df.drop_duplicates()\n",
    "lgftp_df.Date = pd.to_datetime(lgftp_df.Date, errors='coerce')\n",
    "lgftp_df = lgftp_df.sort_values(['Date'])\n",
    "lgftp_df.User = lgftp_df.User.astype(str)\n",
    "lgftp_df['Bytes'] = pd.to_numeric(lgftp_df['Bytes'], errors='coerce')\n",
    "lgftp_df  = lgftp_df.fillna(value=0)\n",
    "lgftp_df['FTP'] = 'LGFTP'\n",
    "lgftp_incoming_df = lgftp_df[lgftp_df[\"Direction\"] == \"i\"]\n",
    "lgftp_df = lgftp_df[lgftp_df[\"Direction\"] == \"o\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the combined Plano-FTP1-FTP2 logs dataframe\n",
    "plano_ftp1_ftp2 = pd.concat([plano_df, ftp2_df, ftp1_df])\n",
    "plano_ftp1_ftp2['Date'] = pd.to_datetime(plano_ftp1_ftp2['Date'], yearfirst = True)\n",
    "plano_ftp1_ftp2[\"Bytes\"] = pd.to_numeric(plano_ftp1_ftp2[\"Bytes\"], errors=\"coerce\")\n",
    "plano_ftp1_ftp2 = plano_ftp1_ftp2.sort_values(['Date', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the combined Plano-LGFTP logs dataframe\n",
    "plano_lgftp = pd.concat([plano_df, lgftp_df], join='inner')\n",
    "plano_lgftp.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldfs_users_file = \"G:\\\\Custom Feeds\\\\LGDF\\\\FTP User lists\\\\LDFS User lists.txt\"\n",
    "lgdf_users_file = \"C:\\\\Users\\\\u0136211\\\\Documents\\\\FTP Logs\\\\LGDF User lists.txt\"\n",
    "custom_feeds_users_file = \"C:\\\\Users\\\\u0136211\\\\Documents\\\\custom feed users.txt\"\n",
    "dfv41_users_file = \"C:\\\\Users\\\\u0136211\\\\Documents\\\\dfv4-1 users.txt\"\n",
    "ghf_user_file = \"C:\\\\Users\\\\u0136211\\\\Documents\\\\ghf users.txt\"\n",
    "ldfs_users = user_lists(ldfs_users_file)\n",
    "custom_feed_users = user_lists(custom_feeds_users_file)\n",
    "dfv41_users = user_lists(dfv41_users_file)\n",
    "ghf_users = user_lists(ghf_user_file)\n",
    "lgdf_users = user_lists(lgdf_users_file)\n",
    "ftp2_users = ftp2_df['User'].unique()\n",
    "len(ftp2_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall('LGDF', lgdf_users, plano_ftp1_ftp2)\n",
    "overall('Custom Feeds', custom_feed_users, plano_ftp1_ftp2)\n",
    "overall('DFV4.1 Feeds', dfv41_users, plano_ftp1_ftp2)\n",
    "overall('GHF Feeds', ghf_users, plano_ftp1_ftp2)\n",
    "overall('LDFS', ldfs_users, plano_lgftp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgdf_comp_inactive_users = set()\n",
    "lgdf_inactive_plano_users = set()\n",
    "lgdf_active_plano_users = set()\n",
    "lgdf_pivots = {}\n",
    "\n",
    "for user in lgdf_users:\n",
    "    temp_p = plano_df[plano_df.User == user]\n",
    "    temp = plano_ftp1_ftp2[plano_ftp1_ftp2.User == user]\n",
    "    if len(temp['Date'].unique()) == 0:\n",
    "        lgdf_comp_inactive_users.add(user)\n",
    "        continue\n",
    "    elif len(temp['Date'].unique()) < 35:\n",
    "        short = \"Y\"\n",
    "        graph_type = \"bar\"\n",
    "        if len(temp_p['Date'].unique()) == 0:\n",
    "            lgdf_inactive_plano_users.add(user)\n",
    "        else:\n",
    "            lgdf_active_plano_users.add(user)\n",
    "        temp[\"Date\"] = temp[\"Date\"].dt.strftime('%Y-%m-%d')\n",
    "        temp = temp.sort_values('Date')\n",
    "    else:\n",
    "        short = \"N\"\n",
    "        graph_type = \"line\"\n",
    "        if len(temp_p['Date'].unique()) == 0:\n",
    "            lgdf_inactive_plano_users.add(user)\n",
    "        else:\n",
    "            lgdf_active_plano_users.add(user)\n",
    "    temp_piv = pd.pivot_table(temp, index=['Date'], columns = ['FTP'], values = ['Bytes'], aggfunc=np.sum, fill_value = 0)\n",
    "    if short == \"N\":\n",
    "        temp_piv = temp_piv.resample('2W').mean()        \n",
    "    temp_plot = temp_piv.plot(legend = True, grid = True, sort_columns = True, colormap='copper', figsize = (8, 4), kind = graph_type, title = (\"Data consumption - \"+user), ylim=(0))    \n",
    "    plt.tight_layout()\n",
    "    temp_plot.figure.savefig(graphs+'%s chart.png' % user)\n",
    "    lgdf_pivots[user] = temp_piv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghf_comp_inactive_users = set()\n",
    "ghf_inactive_plano_users = set()\n",
    "ghf_active_plano_users = set()\n",
    "ghf_pivots = {}\n",
    "\n",
    "for user in ghf_users:\n",
    "    #print(user)\n",
    "    temp_p = plano_df[plano_df.User == user]\n",
    "    temp = plano_ftp1_ftp2[plano_ftp1_ftp2.User == user]\n",
    "    if len(temp['Date'].unique()) == 0:\n",
    "        ghf_comp_inactive_users.add(user)\n",
    "        continue\n",
    "    elif len(temp['Date'].unique()) < 35:\n",
    "        short = \"Y\"\n",
    "        graph_type = \"bar\"\n",
    "        if len(temp_p['Date'].unique()) == 0:\n",
    "            ghf_inactive_plano_users.add(user)\n",
    "        else:\n",
    "            ghf_active_plano_users.add(user)\n",
    "        temp[\"Date\"] = temp[\"Date\"].dt.strftime('%Y-%m-%d')\n",
    "        temp = temp.sort_values('Date')\n",
    "    else:\n",
    "        short = \"N\"\n",
    "        graph_type = \"line\"\n",
    "        if len(temp_p['Date'].unique()) == 0:\n",
    "            ghf_inactive_plano_users.add(user)\n",
    "        else:\n",
    "            ghf_active_plano_users.add(user)\n",
    "    temp_piv = pd.pivot_table(temp, index=['Date'], columns = ['FTP'], values = ['Bytes'], aggfunc=np.sum, fill_value = 0)\n",
    "    if short == \"N\":\n",
    "        temp_piv = temp_piv.resample('2W').mean()        \n",
    "    temp_plot = temp_piv.plot(legend = True, grid = True, sort_columns = True, colormap='copper', figsize = (8, 4), kind = graph_type, title = (\"Data consumption - \"+user), ylim=(0))    \n",
    "    plt.tight_layout()\n",
    "    temp_plot.figure.savefig(graphs+'%s chart.png' % user)\n",
    "    ghf_pivots[user] = temp_piv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfv41_comp_inactive_users = set()\n",
    "dfv41_inactive_plano_users = set()\n",
    "dfv41_active_plano_users = set()\n",
    "dfv41_pivots = {}\n",
    "\n",
    "for user in dfv41_users:\n",
    "    #print(user)\n",
    "    temp_p = plano_df[plano_df.User == user]\n",
    "    temp = plano_ftp1_ftp2[plano_ftp1_ftp2.User == user]\n",
    "    if len(temp['Date'].unique()) == 0:\n",
    "        dfv41_comp_inactive_users.add(user)\n",
    "        continue\n",
    "    elif len(temp['Date'].unique()) < 35:\n",
    "        short = \"Y\"\n",
    "        graph_type = \"bar\"\n",
    "        if len(temp_p['Date'].unique()) == 0:\n",
    "            dfv41_inactive_plano_users.add(user)\n",
    "        else:\n",
    "            dfv41_active_plano_users.add(user)\n",
    "        temp[\"Date\"] = temp[\"Date\"].dt.strftime('%Y-%m-%d')\n",
    "        temp = temp.sort_values('Date')\n",
    "    else:\n",
    "        short = \"N\"\n",
    "        graph_type = \"line\"\n",
    "        if len(temp_p['Date'].unique()) == 0:\n",
    "            dfv41_inactive_plano_users.add(user)\n",
    "        else:\n",
    "            dfv41_active_plano_users.add(user)\n",
    "    temp_piv = pd.pivot_table(temp, index=['Date'], columns = ['FTP'], values = ['Bytes'], aggfunc=np.sum, fill_value = 0)\n",
    "    if short == \"N\":\n",
    "        temp_piv = temp_piv.resample('2W').mean()        \n",
    "    temp_plot = temp_piv.plot(legend = True, grid = True, sort_columns = True, colormap='copper', figsize = (8, 4), kind = graph_type, title = (\"Data consumption - \"+user), ylim=(0))    \n",
    "    plt.tight_layout()\n",
    "    temp_plot.figure.savefig(graphs+'%s chart.png' % user)\n",
    "    dfv41_pivots[user] = temp_piv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldfs_comp_inactive_users = set()\n",
    "ldfs_active_plano_users = set()\n",
    "ldfs_inactive_plano_users = set()\n",
    "ldfs_pivots = {}\n",
    "\n",
    "for user in ldfs_users:\n",
    "    #print(user)\n",
    "    temp_p = plano_df[plano_df.User == user]\n",
    "    temp = plano_lgftp[plano_lgftp.User == user]\n",
    "    if len(temp['Date'].unique()) == 0:\n",
    "        ldfs_comp_inactive_users.add(user)\n",
    "        continue\n",
    "    elif len(temp['Date'].unique()) < 35:\n",
    "        short = \"Y\"\n",
    "        graph_type = \"bar\"\n",
    "        if len(temp_p['Date'].unique()) == 0:\n",
    "            ldfs_inactive_plano_users.add(user)\n",
    "        else:\n",
    "            ldfs_active_plano_users.add(user)\n",
    "        temp[\"Date\"] = temp[\"Date\"].dt.strftime('%Y-%m-%d')\n",
    "        temp = temp.sort_values('Date')\n",
    "    else:\n",
    "        short = \"N\"\n",
    "        graph_type = \"line\"\n",
    "        if len(temp_p['Date'].unique()) == 0:\n",
    "            ldfs_inactive_plano_users.add(user)\n",
    "        else:\n",
    "            ldfs_active_plano_users.add(user)\n",
    "    temp_piv = pd.pivot_table(temp, index=['Date'], columns = ['FTP'], values = ['Bytes'], aggfunc=np.sum, fill_value = 0)\n",
    "    if short == \"N\":\n",
    "        temp_piv = temp_piv.resample('2W').mean()        \n",
    "    temp_plot = temp_piv.plot(legend = True, grid = True, sort_columns = True, colormap='copper', figsize = (8, 4), kind = graph_type, title = (\"Data consumption - \"+user), ylim=(0))    \n",
    "    plt.tight_layout()\n",
    "    temp_plot.figure.savefig(graphs+'%s chart.png' % user)\n",
    "    ldfs_pivots[user] = temp_piv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_feeds_comp_inactive_users = set()\n",
    "custom_feeds_inactive_plano_users = set()\n",
    "custom_feeds_active_plano_users = set()\n",
    "custom_feeds_pivots = {}\n",
    "\n",
    "for user in custom_feed_users:\n",
    "    #print(user)\n",
    "    temp_p = plano_df[plano_df.User == user]\n",
    "    temp = plano_ftp1_ftp2[plano_ftp1_ftp2.User == user]\n",
    "    if len(temp['Date'].unique()) == 0:\n",
    "        custom_feeds_comp_inactive_users.add(user)\n",
    "        continue\n",
    "    elif len(temp['Date'].unique()) < 35:\n",
    "        short = \"Y\"\n",
    "        graph_type = \"bar\"\n",
    "        if len(temp_p['Date'].unique()) == 0:\n",
    "            custom_feeds_inactive_plano_users.add(user)\n",
    "        else:\n",
    "            custom_feeds_active_plano_users.add(user)\n",
    "        temp[\"Date\"] = temp[\"Date\"].dt.strftime('%Y-%m-%d')\n",
    "        temp = temp.sort_values('Date')\n",
    "    else:\n",
    "        short = \"N\"\n",
    "        graph_type = \"line\"\n",
    "        if len(temp_p['Date'].unique()) == 0:\n",
    "            custom_feeds_inactive_plano_users.add(user)\n",
    "        else:\n",
    "            custom_feeds_active_plano_users.add(user)\n",
    "    temp_piv = pd.pivot_table(temp, index=['Date'], columns = ['FTP'], values = ['Bytes'], aggfunc=np.sum, fill_value = 0)\n",
    "    if short == \"N\":\n",
    "        temp_piv = temp_piv.resample('2W').mean()        \n",
    "    temp_plot = temp_piv.plot(legend = True, grid = True, sort_columns = True, colormap='copper', figsize = (8, 4), kind = graph_type, title = (\"Data consumption - \"+user), ylim=(0))    \n",
    "    plt.tight_layout()\n",
    "    temp_plot.figure.savefig(graphs+'%s chart.png' % user)\n",
    "    custom_feeds_pivots[user] = temp_piv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ldfs_comp_inactive_users = sorted(list(ldfs_comp_inactive_users))\n",
    "ldfs_comp_inactive_users_df = pd.DataFrame(ldfs_comp_inactive_users, columns=[\"Completely Inactive Users\"])\n",
    "ldfs_comp_inactive_users_df = ldfs_comp_inactive_users_df.set_index(\"Completely Inactive Users\")\n",
    "\n",
    "ldfs_inactive_plano_users = sorted(list(ldfs_inactive_plano_users))\n",
    "ldfs_inactive_plano_users_df = pd.DataFrame(ldfs_inactive_plano_users, columns=[\"Inactive Plano Users\"])\n",
    "ldfs_inactive_plano_users_df = ldfs_inactive_plano_users_df.set_index(\"Inactive Plano Users\")\n",
    "\n",
    "ldfs_active_plano_users = sorted(list(ldfs_active_plano_users))\n",
    "ldfs_active_plano_users_df = pd.DataFrame(ldfs_active_plano_users, columns=[\"Active Plano Users\"])\n",
    "ldfs_active_plano_users_df = ldfs_active_plano_users_df.set_index(\"Active Plano Users\")\n",
    "\n",
    "ghf_comp_inactive_users = sorted(list(ghf_comp_inactive_users))\n",
    "ghf_comp_inactive_users_df = pd.DataFrame(ghf_comp_inactive_users, columns=[\"Completely Inactive Users\"])\n",
    "ghf_comp_inactive_users_df = ghf_comp_inactive_users_df.set_index(\"Completely Inactive Users\")\n",
    "\n",
    "ghf_inactive_plano_users = sorted(list(ghf_inactive_plano_users))\n",
    "ghf_inactive_plano_users_df = pd.DataFrame(ghf_inactive_plano_users, columns=[\"Inactive Plano Users\"])\n",
    "ghf_inactive_plano_users_df = ghf_inactive_plano_users_df.set_index(\"Inactive Plano Users\")\n",
    "\n",
    "ghf_active_plano_users = sorted(list(ghf_active_plano_users))\n",
    "ghf_active_plano_users_df = pd.DataFrame(ghf_active_plano_users, columns=[\"Active Plano Users\"])\n",
    "ghf_active_plano_users_df = ghf_active_plano_users_df.set_index(\"Active Plano Users\")\n",
    "\n",
    "lgdf_comp_inactive_users = sorted(list(lgdf_comp_inactive_users))\n",
    "lgdf_comp_inactive_users_df = pd.DataFrame(lgdf_comp_inactive_users, columns=[\"Completely Inactive Users\"])\n",
    "lgdf_comp_inactive_users_df = lgdf_comp_inactive_users_df.set_index(\"Completely Inactive Users\")\n",
    "\n",
    "lgdf_inactive_plano_users = sorted(list(lgdf_inactive_plano_users))\n",
    "lgdf_inactive_plano_users_df = pd.DataFrame(lgdf_inactive_plano_users, columns=[\"Inactive Plano Users\"])\n",
    "lgdf_inactive_plano_users_df = lgdf_inactive_plano_users_df.set_index(\"Inactive Plano Users\")\n",
    "\n",
    "lgdf_active_plano_users = sorted(list(lgdf_active_plano_users))\n",
    "lgdf_active_plano_users_df = pd.DataFrame(lgdf_active_plano_users, columns=[\"Active Plano Users\"])\n",
    "lgdf_active_plano_users_df = lgdf_active_plano_users_df.set_index(\"Active Plano Users\")\n",
    "\n",
    "custom_feeds_comp_inactive_users = sorted(list(custom_feeds_comp_inactive_users))\n",
    "custom_feeds_comp_inactive_users_df = pd.DataFrame(custom_feeds_comp_inactive_users, columns=[\"Completely Inactive Users\"])\n",
    "custom_feeds_comp_inactive_users_df = custom_feeds_comp_inactive_users_df.set_index(\"Completely Inactive Users\")\n",
    "\n",
    "custom_feeds_inactive_plano_users = sorted(list(custom_feeds_inactive_plano_users))\n",
    "custom_feeds_inactive_plano_users_df = pd.DataFrame(custom_feeds_inactive_plano_users, columns=[\"Inactive Plano Users\"])\n",
    "custom_feeds_inactive_plano_users_df = custom_feeds_inactive_plano_users_df.set_index(\"Inactive Plano Users\")\n",
    "\n",
    "custom_feeds_active_plano_users = sorted(list(custom_feeds_active_plano_users))\n",
    "custom_feeds_active_plano_users_df = pd.DataFrame(custom_feeds_active_plano_users, columns=[\"Active Plano Users\"])\n",
    "custom_feeds_active_plano_users_df = custom_feeds_active_plano_users_df.set_index(\"Active Plano Users\")\n",
    "\n",
    "dfv41_comp_inactive_users = sorted(list(dfv41_comp_inactive_users))\n",
    "dfv41_comp_inactive_users_df = pd.DataFrame(dfv41_comp_inactive_users, columns=[\"Completely Inactive Users\"])\n",
    "dfv41_comp_inactive_users_df = dfv41_comp_inactive_users_df.set_index(\"Completely Inactive Users\")\n",
    "\n",
    "dfv41_inactive_plano_users = sorted(list(dfv41_inactive_plano_users))\n",
    "dfv41_inactive_plano_users_df = pd.DataFrame(dfv41_inactive_plano_users, columns=[\"Inactive Plano Users\"])\n",
    "dfv41_inactive_plano_users_df = dfv41_inactive_plano_users_df.set_index(\"Inactive Plano Users\")\n",
    "\n",
    "dfv41_active_plano_users = sorted(list(dfv41_active_plano_users))\n",
    "dfv41_active_plano_users_df = pd.DataFrame(dfv41_active_plano_users, columns=[\"Active Plano Users\"])\n",
    "dfv41_active_plano_users_df = dfv41_active_plano_users_df.set_index(\"Active Plano Users\")\n",
    "\n",
    "legend = pd.DataFrame({\"Table\" : [\"Completely Inactive Users\", \"Inactive Plano Users\", \"Active Plano Users\"], \"Key\" : [\"These users have not, according to the logs, downloaded a single file from either Denver or Plano servers\", \"These users have not, according to the logs, downloaded a single file the Plano server\", \"These users are actively downloading files from the Plano sever\"]})\n",
    "legend = legend.set_index(\"Table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_xls(profile, pivots, active_users_df, inactive_users_df, comp_inactive_users_df, legend, xlsx_path):\n",
    "    writer = pd.ExcelWriter(xlsx_path, engine='xlsxwriter')\n",
    "    workbook = writer.book\n",
    "    worksheet = workbook.add_worksheet(\"Overall Progress\")\n",
    "    worksheet.insert_image('B2', graphs+'Overall %s.png' % profile)\n",
    "    legend.to_excel(writer, \"Users\", startrow = 0, startcol = 1)\n",
    "    active_users_df.to_excel(writer, \"Users\", startrow = 5, startcol = 1)\n",
    "    inactive_users_df.to_excel(writer, \"Users\", startrow = 5, startcol = 4)\n",
    "    comp_inactive_users_df.to_excel(writer, \"Users\", startrow = 5, startcol = 7)\n",
    "    for user, df in sorted(pivots.items()):\n",
    "        df.to_excel(writer,'%s' % user)\n",
    "        piv_t = '%s' % user\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets['%s' % user]\n",
    "        worksheet.insert_image('F3', graphs+\"%s chart.png\" % user)\n",
    "    writer.save()\n",
    "    \n",
    "save_xls(\"DFV4.1 Feeds\", dfv41_pivots, dfv41_active_plano_users_df, dfv41_inactive_plano_users_df, dfv41_comp_inactive_users_df,  legend, \"C:\\\\Users\\\\u0136211\\\\Documents\\\\FTP Logs\\\\dfv4 Plano FTP usage.xlsx\")\n",
    "save_xls(\"Custom Feeds\", custom_feeds_pivots, custom_feeds_active_plano_users_df, custom_feeds_inactive_plano_users_df, custom_feeds_comp_inactive_users_df,  legend, \"C:\\\\Users\\\\u0136211\\\\Documents\\\\FTP Logs\\\\Custom Feeds Plano FTP usage.xlsx\")\n",
    "save_xls(\"GHF Feeds\", ghf_pivots, ghf_active_plano_users_df, ghf_inactive_plano_users_df, ghf_comp_inactive_users_df,  legend, \"C:\\\\Users\\\\u0136211\\\\Documents\\\\FTP Logs\\\\Global Holdings Feed Plano FTP usage.xlsx\")\n",
    "save_xls(\"LGDF\", lgdf_pivots, lgdf_active_plano_users_df, lgdf_inactive_plano_users_df, lgdf_comp_inactive_users_df,  legend, lgdf_output)\n",
    "save_xls(\"LDFS\", ldfs_pivots, ldfs_active_plano_users_df, ldfs_inactive_plano_users_df, ldfs_comp_inactive_users_df, legend, ldfs_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
